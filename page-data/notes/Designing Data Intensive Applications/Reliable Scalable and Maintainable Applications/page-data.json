{"componentChunkName":"component---src-templates-note-template-js","path":"/notes/Designing Data Intensive Applications/Reliable Scalable and Maintainable Applications/","webpackCompilationHash":"1307dca3626bbb061791","result":{"data":{"markdownRemark":{"html":"<h1>Reliable, Scalable and Maintainable Applications</h1>\n<p>Exploration of the fundamentals of what we are trying to achieve: reliable, scalable, and maintainable data systems.</p>\n<blockquote>\n<p>The Internet was done so well that most people think of it as a natural resource like the Pacific Ocean, rather than something that was man-made. When was the last time a technology with a scale like that was so error-free?\n— Alan Kay, in an interview with Dr. Dobb’s Journal (2012)</p>\n</blockquote>\n<ul>\n<li>\n<p>Basic necessities of any application:</p>\n<ul>\n<li>Databases</li>\n<li>Caches</li>\n<li>Search Indexes</li>\n<li>Stream processing</li>\n<li>Batch processing</li>\n</ul>\n</li>\n</ul>\n<h2>Thinking about data systems</h2>\n<ul>\n<li>Although a database and a message queue have some superficial similarity both store data for some time they have very different access patterns, which means different performance characteristics, and thus very different implementations.</li>\n<li>\n<p>Recent technologies have emerged which incorporate both of these ideas:</p>\n<ul>\n<li>Reddis: Datastores that use messaging queue</li>\n<li>Apache Kafka: Message queues with database-like durability</li>\n</ul>\n</li>\n<li>⇒ It is application code's responsibility to maintain sync between a database and an external service like Memcached or ElasticSearch.</li>\n<li>\n<p>Three concerns that are important in most software systems:</p>\n<ul>\n<li>Reliability: Should respond with correct functions at all times</li>\n<li>Scalability: Should grow with load</li>\n<li>Maintainability: Both in terms of engineering and operational</li>\n</ul>\n</li>\n</ul>\n<h2>Reliability</h2>\n<ul>\n<li>A system should work correctly even when things go wrong</li>\n<li><strong>Fault:</strong> things that go wrong</li>\n<li><strong>Fault-tolerant</strong> systems can cope up and anticipate faults</li>\n</ul>\n<blockquote>\n<p>The former term is slightly misleading: it suggests that we could make a system tolerant of every possible kind of fault, which in reality is not feasible. If the entire planet Earth (and all servers on it) were swallowed by a black hole, tolerance of that fault would require web hosting in space - <strong><em>good luck getting that budget item approved</em></strong>. So it only makes sense to talk about tolerating certain types of faults.</p>\n</blockquote>\n<ul>\n<li><strong>Failure:</strong> When a system as a whole stops functioning</li>\n<li>Counterintuitively, it makes sense to introduce faults into the system to measure the performance under stress. Netflix does the same with Choas Monkey</li>\n</ul>\n<h3>Hardware Faults</h3>\n<ul>\n<li>Such systems occurr all the time when you have large number of machines</li>\n<li>HDD's have a mean time to failure(MTTF) of 10-50 years. This means a storage system having 10,000 HDD's should expect a death of one disk a day.</li>\n<li>A normal way of dealing with them is to introduce the concept of RAID configuration(redundant array of independent disks). When one component dies, another component can replace it. This can often keep a system running for a few years.</li>\n<li>This was enough when the systems were not data-intensive, but now applications crunch a huge amount of data which use more number of machines. This has lead to a proportional increase in hardware faults.</li>\n</ul>\n<h3>Software Errors</h3>\n<ul>\n<li>These type of failures are harder to anticipate since they comprise of a lot of components.</li>\n<li>A runaway process that uses up some shared resource—CPU time, memory, disk space, or network bandwidth.</li>\n<li>A service that the system depends on that slows down, becomes unresponsive, or\nstarts returning corrupted responses.</li>\n<li>Cascading failures, where a small fault in one component triggers a fault in\nanother component, which in turn triggers further faults.</li>\n</ul>\n<h3>Human Errors</h3>\n<ul>\n<li>A study showed that majority of the errors were caused due to human unrealiability.</li>\n</ul>\n<h2>Scalability</h2>\n<p>Even if a system is working reliably today, that doesn’t mean it will necessarily work\nreliably in the future.</p>\n<p><strong>Scalability:</strong> A system's ability to cope with increased load</p>\n<p>Different systems will have different <em>Load Parameters.</em></p>\n<h3>Describing Load:</h3>\n<p><strong>Case Study: Twitter 2012</strong></p>\n<ul>\n<li>Post Tweet Req: 4.6K req/sec[average], 12K req/sec [peak]</li>\n<li>Home Timeline: 300K req/sec</li>\n<li>12K writes/sec is not an issue for them</li>\n<li>But the major issue is: <strong><em>fan-out —</em></strong> each user follows many users, and each user is followed by many users.</li>\n</ul>\n<h3>Describing Performance:</h3>\n<ul>\n<li>When you increase a load parameter and keep the system resources unchanged, how is the performance of your system affected?</li>\n<li>When you increase your load parameter, how much do you need to increase the resources to keep the performances unchanged?</li>\n<li><strong>Throughput:</strong> The number of records we can process per second</li>\n<li><strong>Response Time:</strong> Time between client making a requst and recieving a response</li>\n<li>Median is a better metric than mean when it comes to measuring response time, because mean does not tell you how many users experienced a delay.</li>\n<li>Usually, percentiles are used. p50 is for 50th percentile and similary p95, p99.9</li>\n<li>Percentiles are often used when defining <em>Service Level Objectives and Service Level Agreements.</em></li>\n<li><strong>Head-of-line Blocking:</strong> A small number of sloq requests that hold up the entire processing of subsequent requests.</li>\n</ul>\n<p><strong>Case Study: Amazon</strong></p>\n<ul>\n<li>Amazon describes response time requirements for internal services in terms of the 99.9th percentile, even though it only affects 1 in 1,000 requests.</li>\n<li>This is because the customers with the slowest requests are often those who have the most data on their accounts because they have made many purchases—that is, they’re the most valuable customers. It’s important to keep those customers happy by ensuring the website is fast for them.</li>\n<li>Amazon has also observed that a 100 ms increase in response time reduces sales by 1%, and others report that a 1-second slowdown reduces a customer satisfaction metric by 16%.</li>\n</ul>\n<h3>Approaches for coping with load</h3>\n<ul>\n<li><strong>Scaling Up or Vertical Scaling:</strong> Making machines more powerful</li>\n<li><strong>Scaling Out or Horizontal Scaling:</strong> Adding more machines across systems</li>\n<li><strong>Elastic:</strong> Systems that can automatically add computing resources when they detect load</li>\n</ul>\n<h2>Maintainability</h2>\n<p>Three major design principles:</p>\n<h3>Operability: make it easy for different teams</h3>\n<ul>\n<li>Providing visibility into the runtime behavior and internals of the system, with good monitoring</li>\n<li>Avoiding dependency on individual machines</li>\n<li>Keep tabs on how different systems affect each other</li>\n<li>Providing good documentation and an easy-to-understand operational model</li>\n</ul>\n<h3><strong>Simplicity:</strong> make it easy for new engineers</h3>\n<ul>\n<li><strong>Abstraction:</strong> one of the best ways to to achieve simplicity</li>\n</ul>\n<h3><strong>Evolvability:</strong> <strong>make it easy for future changes</strong></h3>\n<ul>\n<li>Agile is one way to tackle and adapt to new changes</li>\n</ul>","frontmatter":{"date":"May 08, 2020","title":"Reliable, Scalable and Maintainable Applications"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/notes/Designing Data Intensive Applications/Reliable Scalable and Maintainable Applications/"}}}