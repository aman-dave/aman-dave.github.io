{"componentChunkName":"component---src-templates-note-template-js","path":"/notes/Designing Data Intensive Applications/Storage and Retrieval/","webpackCompilationHash":"1307dca3626bbb061791","result":{"data":{"markdownRemark":{"html":"<h1>Storage and Retrieval</h1>\n<blockquote>\n<p>If you keep things tidily ordered, you’re just too lazy to go searching.\n— German Proverb</p>\n</blockquote>\n<ul>\n<li>Many databases internally use a <strong>log</strong>, which is an append-only data file.</li>\n<li>In order to efficiently find the value for a particular key in the database, we use an index — an additional structure that is derived from the primary data.</li>\n<li>An important trade-off in storage systems: well-chosen indexes speed up read queries, but every index slows down writes.</li>\n</ul>\n<h1>Hash Indexes</h1>\n<ul>\n<li>The simplest possible indexing strategy is to keep an in-memory hash map where every key is mapped to a byte offset in the data file—the location at which the value can be found.</li>\n<li>A good way to make sure we don't run out of space is to break the log into segments of a certain size and closing the segment when it reaches a certain size limit and then writing into a new segment.</li>\n<li>We can then perform compaction on these segments.</li>\n<li><strong>Compaction</strong> means throwing away duplicate keys in the log, and keeping only the most recent update for each key.</li>\n<li>We could also merge several segments before performing compaction.</li>\n<li>Compaction results in smaller segments.</li>\n</ul>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 596px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/7f31be2acc7be769b4ec0f52aeba07a7/67e88/Untitled.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.51006711409396%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsSAAALEgHS3X78AAABNklEQVQoz12SiXLCMAxE8/9/WCahcU47vgI5CAMNfciF6bBjNEKyVis52ePxiDFUler7vm3bEPxNcOfc7zexH84b2b7vlBVFUZZl0zRKlfx11tZ13eE493S6zlpbVTUXrKRo473P5nnqBcaYeZ7btuFqCGiptNYxhO/j0XuHo5T6SylFNlC8rqt3juJhGIzR8BG5CLZtSz7O08q5vCzI1mVBw9fhkOd5KfAhxDgKlxnHkf7WDjQkguYYY0qdTqeMH8XMRpQOXCVHEIU40zQxp3P2fD4zkdH6nYI3g4NtQYlg6I3AC0ZBcihODd6RZ2emhUlW1mndc7qOBwv7C7wl9keQXis5WLY9I6wociU7hIOXgHtZFjSzsFnARInoP7Lr9cqc8nkEtEFEc4qTHIKkGAqRfBUfxb9yqi+yA+HwhQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"Storage and Retrieval.png\"\n        title=\"\"\n        src=\"/static/7f31be2acc7be769b4ec0f52aeba07a7/67e88/Untitled.png\"\n        srcset=\"/static/7f31be2acc7be769b4ec0f52aeba07a7/d4214/Untitled.png 150w,\n/static/7f31be2acc7be769b4ec0f52aeba07a7/135ae/Untitled.png 300w,\n/static/7f31be2acc7be769b4ec0f52aeba07a7/67e88/Untitled.png 596w\"\n        sizes=\"(max-width: 596px) 100vw, 596px\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Storage and Retrieval.png</figcaption>\n  </figure></p>\n<ul>\n<li>\n<p>Advantages of append-only designs:</p>\n<ul>\n<li>Appending and segment merging are sequential operations</li>\n<li>They are generally much faster than random writes, especially on magnetic HDD</li>\n<li>Concurrency and crash recovery are much simpler</li>\n<li>Merging old segments avoids the problem of data files getting fragmented over time</li>\n</ul>\n</li>\n<li>\n<p>Disadvantages:</p>\n<ul>\n<li>The hash table must fit in memory</li>\n<li>Range queries are not efficient</li>\n</ul>\n</li>\n</ul>\n<h1>SSTables and LSM-Trees</h1>\n<ul>\n<li>\n<p><strong>Sorting String Table</strong></p>\n<ul>\n<li>Segments are a sequence of key-value pairs</li>\n<li>For SSTables we sort the keys of segments</li>\n<li>We merge sorted segments similar to how mergesort is performed</li>\n<li>We can group several records onto a block and compress it and then write it to a disk. Each entry in the sparse in-memory index then points at the start of a compressed block. This also helps in saving I/O bandwidth</li>\n</ul>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/5055ab6a7242a1c2c24679cbf2088bf1/b9e4f/Untitled1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50.33898305084745%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsSAAALEgHS3X78AAABHklEQVQoz32R3ZKDIAxGff8H9FJdAQWt/1pdtbIHWDu92NkzNhMCX5ImUd/3yzJPE9/09MzzPAzDOI7Dzegh/rxZ17XruohQWZZKybZtrbXneTZN83DUbevcqqoax2PbNuu5rgtLiqjvB6UKpZTWJUVIQS8hy+uD4zioZkxljFmWhVtsxGta4oBjjBZC5DlGSCm01ljyIsDm+RdkWZamKVd1XUe0LqXEo6vc68I1BD9JEuKIiSBOPJQgoxNzIBP14zg2Dp0mibxB6YeiUAqfxYvFrzj8jX3fcSjFdXjNFEgajkVRhCCgZEEUi9gQw/j2oKd/ImExZGSkHN9+cLDMyE2bn/2Ai21b7b9cHiembXbwXj1iFvuO/AnFecB2fgCyRjEcCWjnRQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"SS Tables.png\"\n        title=\"\"\n        src=\"/static/5055ab6a7242a1c2c24679cbf2088bf1/b9e4f/Untitled1.png\"\n        srcset=\"/static/5055ab6a7242a1c2c24679cbf2088bf1/d4214/Untitled1.png 150w,\n/static/5055ab6a7242a1c2c24679cbf2088bf1/135ae/Untitled1.png 300w,\n/static/5055ab6a7242a1c2c24679cbf2088bf1/b9e4f/Untitled1.png 590w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">SS Tables.png</figcaption>\n  </figure></p>\n<h3>Constructing and maintaining SSTables</h3>\n<ol>\n<li>When a write comes in, add it to an in-memory balanced tree data structure (for\nexample, a red-black tree). This in-memory tree is sometimes called a memtable.</li>\n<li>When the memtable gets bigger than some threshold—typically a few megabytes\n—write it out to disk as an SSTable file. This can be done efficiently because the\ntree already maintains the key-value pairs sorted by key. The new SSTable file\nbecomes the most recent segment of the database. While the SSTable is being\nwritten out to disk, writes can continue to a new memtable instance.</li>\n<li>In order to serve a read request, first, try to find the key in the memtable, then in\nthe most recent on-disk segment, then in the next-older segment, etc.</li>\n<li>From time to time, run a merging and compaction process in the background to\ncombine segment files and to discard overwritten or deleted values.</li>\n</ol>\n<h3>Making LSM-Tree out of SSTables</h3>\n<ul>\n<li><strong>Log-Structured Merge-Tree:</strong> basic idea of keeping a cascade of SSTables that are merged in the background</li>\n<li>\n<p>Different strategies to merge — <em>size-tiered and leveled compaction</em></p>\n<ul>\n<li><strong>Size Tiered</strong> — newer and smaller SSTables are successively merged into older and larger SSTables</li>\n<li><strong>Leveled Compaction</strong> — the key range is split up into smaller SSTables and older data is moved into separate “levels,” which allows the compaction to proceed more incrementally and use less disk space</li>\n</ul>\n</li>\n<li>LSM-Tree algorithm can be slow when looking up keys that do not exist in the database</li>\n<li><strong>Bloom filter</strong> is a memory-efficient data structure for approximating the contents of a set. It can tell you if a key does not appear in the database, and thus saves many unnecessary disk reads for nonexistent keys</li>\n</ul>\n</li>\n</ul>\n<h2>B-Trees</h2>\n<ul>\n<li>The log-structured indexes break down the database into variable size segments, whereas <strong>B-Trees</strong> break down the database into fixed-size blocks</li>\n<li>Each page can be accessed with a pointer, on a disk instead of in memory</li>\n<li>One page is declared as the root, and contains pointers to its child</li>\n<li>The pages contain several keys and references to child</li>\n<li>Each child is responsible for a continuous range of keys, and the keys between the references indicate where the boundaries between those ranges lie</li>\n<li><strong>Branching Factor:</strong> number of child references a page can hold</li>\n<li>B-tree with n keys always has a depth of <em>O(log n)</em></li>\n<li><em>A four-level tree of 4 KB pages with a branching factor of 500 can store up to 256 TB</em></li>\n</ul>\n<h3>Making B-trees reliable</h3>\n<ul>\n<li><strong>Write-Ahead Log(Redo Log):</strong> an append-only file to which every B-tree modification must be written before it can be applied to the pages of the tree itself</li>\n<li><strong>Latches(lightweight locks):</strong> protects tree's data structure against being inconsistent</li>\n</ul>\n<h2>Comparing B-Trees and LSM-Trees</h2>\n<ul>\n<li>LSM-Trees are typically faster writes and B-Trees are typically faster reads</li>\n<li>Reads on LSM-Trees are generally slower because they have to check various data structures and SS-Tables at different stages of compaction</li>\n<li>B-Tree writes every piece of data twice — once to the write-ahead log and once to the tree page. It may happen more than twice depending on certain situations</li>\n<li>\n<p><em>Write amplification</em> — one write to the database causes multiple writes to the disk over the course of database's lifetime</p>\n<ul>\n<li>Especially in SSD's which can only do overwrites a limited number of times before wearing out</li>\n</ul>\n</li>\n<li>\n<p>In write-heavy applications, the performance bottleneck might be the rate at which the database can write to disk</p>\n<ul>\n<li>In this case, write amplification has a direct performance cost: the more that a storage engine writes to disk, the fewer writes per second it can handle within the available disk bandwidth</li>\n</ul>\n</li>\n<li>\n<p>Magnetic hard drives have sequential writes much faster than random writes</p>\n<ul>\n<li>This means the sequential writes in SS-Tables helps in performance</li>\n</ul>\n</li>\n<li>LSM-Trees are compressed better, whereas B-Tree storage engines leave some disk space unused due to fragmentation</li>\n<li>Due to the compaction process, sometimes the ongoing read and write suffer</li>\n<li>If throughput is very high and compaction is not configured correctly, compaction may not be able to keep up with the incoming writes. This means over a period of time the disk may run out of space</li>\n</ul>\n<h2>Transaction Processing or Analytics</h2>\n<ul>\n<li>Transaction processing just means allowing clients to make low-latency reads and writes as opposed to batch processing jobs</li>\n<li><em>OLTP</em>: Online Transaction Processing</li>\n<li><em>OLAP</em>: Online Analytics Processing</li>\n</ul>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 600px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/137baa22a8d4e36749d581cd7976aa02/77dff/Screenshot_from_2020-06-26_12-41-07.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 71.54340836012861%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsSAAALEgHS3X78AAABW0lEQVQoz2WSSZaDMAxEuf8dWZAHYR7NPCU/LnDyumthJKGSS5K9uq6NMZNFf2O6YSzath3HEZcT1yV4TdPAf1n0vcHtuu51A9v3/SzLXKSqqscjkO1RjM9xHOd5rut6WhDhJPg/siyLkj9kJCGDpDzPoyjMsnQYBv4hL47jMAyjKJKWoihiCxfx0EyUbEqWZTnP87ZtuJxEcPnrIrjkE8e+yHBQQj36QYIU8pv48/kkQakwcRmKan3IyCOKwywRvG27WjosxnFgKBik7vtOAkPGUOQamCrN8yTDQeKdC+3XvcgAecjm32pBbZgMJkkSJqoqgM2SdpG7rjXmWiwEStCYCPQcBAFNojZNU4bCarj8e7Oddi7lbqUSosfEtOEr+Jtwkdkw8qRZT4VsboDM26qqUr2gXFP8kjVtSrB9+icJlyAGajmpS/XMQnv5OzD3AN0aZGsxLkE3uwbf0qgrwfc/ghYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"OLTP vs OLAP\"\n        title=\"\"\n        src=\"/static/137baa22a8d4e36749d581cd7976aa02/34e8a/Screenshot_from_2020-06-26_12-41-07.png\"\n        srcset=\"/static/137baa22a8d4e36749d581cd7976aa02/d4214/Screenshot_from_2020-06-26_12-41-07.png 150w,\n/static/137baa22a8d4e36749d581cd7976aa02/135ae/Screenshot_from_2020-06-26_12-41-07.png 300w,\n/static/137baa22a8d4e36749d581cd7976aa02/34e8a/Screenshot_from_2020-06-26_12-41-07.png 600w,\n/static/137baa22a8d4e36749d581cd7976aa02/77dff/Screenshot_from_2020-06-26_12-41-07.png 622w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">OLTP vs OLAP</figcaption>\n  </figure></p>","frontmatter":{"date":"May 18, 2020","title":"Storage and Retrieval"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/notes/Designing Data Intensive Applications/Storage and Retrieval/"}}}